{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324abfa0",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../Machine Learning Aplicado al Marketing-4875-x-834.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c7c13",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ignaciomsarmiento/MALM/blob/main/04_Cluster_Jerarquico/04_Clusterin_Jerarquico_clase.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f061327",
   "metadata": {},
   "source": [
    "# Segmentación de clientes basada en datos\n",
    "\n",
    "La segmentación de clientes es fundamental en el marketing moderno, permitiendo:\n",
    "\n",
    "1. Entender mejor los diferentes comportamientos de los clientes\n",
    "2. Crear estrategias de marketing más efectivas y personalizadas\n",
    "3. Optimizar recursos al dirigirse a grupos específicos\n",
    "\n",
    "## Analisis de clusters\n",
    "\n",
    "\n",
    "El análisis de clusters es una herramienta poderosa para identificar estos segmentos de mercado, pero presenta algunos desafíos importantes:\n",
    "\n",
    "- Los datos de consumidores raramente están bien estructurados\n",
    "- Las preferencias de los clientes suelen distribuirse de forma continua, sin grupos claramente definidos\n",
    "- El resultado final depende tanto de los datos como del algoritmo seleccionado\n",
    "\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    <img src = \"figs/plot_clustering_notebook.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "Existen principalmente dos enfoques para el clustering en marketing:\n",
    "1. Métodos basados en distancia: Agrupan clientes según su similitud\n",
    "2. Métodos basados en modelos: Utilizan modelos estadísticos para definir los segmentos\n",
    "\n",
    "\n",
    "En clases anteriores, estudiamos el algoritmo de k-medias, uno de los métodos más populares para la segmentación de clientes. Recordemos que k-medias:\n",
    "\n",
    "- Agrupa los clientes en un número predefinido (k) de segmentos\n",
    "- Funciona iterativamente asignando cada cliente al centroide más cercano\n",
    "- Es intuitivo y fácil de interpretar en contextos de marketing\n",
    "- Requiere que especifiquemos el número de segmentos de antemano\n",
    "\n",
    "Sin embargo, k-medias tiene algunas limitaciones:\n",
    "- Asume que los clusters son circulares o esféricos\n",
    "- No maneja bien grupos de diferentes tamaños o densidades\n",
    "- No detecta outliers o casos atípicos\n",
    "\n",
    "Esto nos lleva a explorar métodos más avanzados como el clustering jerárquico y DBSCAN, que pueden superar algunas de estas limitaciones y ofrecer nuevas perspectivas en la segmentación de clientes.\n",
    "\n",
    "La clave está en entender que no existe un método \"perfecto\" - cada algoritmo tiene sus fortalezas y debilidades. La elección del método dependerá de:\n",
    "- Las características de nuestros datos\n",
    "- Los objetivos específicos de la segmentación\n",
    "- Los requisitos del negocio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c385d",
   "metadata": {},
   "source": [
    "### Etapas generales\n",
    "\n",
    "Las etapas del análisis de clusters podemos resumirlas de la siguiente forma:\n",
    "\n",
    "1. Iniciamos con una matriz de datos\n",
    "\n",
    "    \\begin{align}\n",
    "X_{n\\times k}=\\left(\\begin{array}{cccc}\n",
    "x_{11} &  & \\dots & x_{1k}\\\\\n",
    "\\\\\n",
    "\\vdots &  & x_{ik} & \\vdots\\\\\n",
    "\\\\\n",
    "x_{n1} &  & \\dots & x_{nk} \n",
    "\\end{array}\\right)\n",
    "    \\end{align}\n",
    "\n",
    "2. Calculamos la matriz de distancia o disimilitud\n",
    "\n",
    "\\begin{align}\n",
    "D_{n\\times n}=\\left(\\begin{array}{ccccc}\n",
    "d_{11} &  & \\dots &  & d_{1n}\\\\\n",
    " & \\ddots\\\\\n",
    "\\vdots &  & d_{jj} &  & \\vdots\\\\\n",
    " &  &  & \\ddots\\\\\n",
    "d_{n1} &  & \\dots &  & d_{nn}\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "3. Aplicamos el algoritmo de clustering. Existen varios tipos\n",
    "    - **basados en centroides**\n",
    "    - **basados en conectividad** \n",
    "    - **basados en densidades**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c63f4",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico\n",
    "\n",
    "- El clustering jerárquico es especialmente útil cuando no existen expectativas sobre los patrones y estructuras subyacentes de los datos.\n",
    "\n",
    "\n",
    "Los métodos de agrupamiento jerárquico son la forma más intuitiva de agrupar datos porque imitan la forma en que un humano abordaría la tarea de dividir un conjunto de n observaciones (consumidores) en k grupos (segmentos). \n",
    "     - Si el objetivo es tener un gran segmento de mercado (k = 1), la única solución posible es un gran segmento de mercado que contenga a todos los consumidores en los datos X. \n",
    "     - En el otro extremo, si el objetivo es tener tantos segmentos de mercado como consumidores en el conjunto de datos (k = n), el número de segmentos de mercado tiene que ser n, y cada segmento debe contener exactamente un consumidor.\n",
    "\n",
    "- Cada consumidor representa su propio grupo. El análisis de segmentación de mercado se produce entre esos dos extremos.\n",
    "\n",
    "\n",
    "\n",
    "<div >\n",
    "    <img src = \"figs/WallStreet.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "<div >\n",
    "    <img src = \"figs/Harrans.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "- Una característica atractiva es que no es necesario especificar el número de clusers a buscar a priori como en   k-medias \n",
    "\n",
    "\n",
    "- Este  mide la conectividad entre las observaciones en algún espacio de características o conjunto de datos. \n",
    "\n",
    "\n",
    "- Podemos usar los resultados para visualizar su similitud espacial entre sí en una variedad de niveles, típicamente en forma de dendrograma, que es una estructura similar a un árbol que muestra progresivamente las similitudes entre las observaciones.\n",
    "\n",
    "\n",
    "- En algunos casos puede informar a los otros métodos de clustering  basados en los patrones revelados. Por ejemplo, si el dendrograma revela dos grupos naturales, entonces una segunda etapa puede inicializar un algoritmo de k-medias con dos conglomerados. Al especificar el algoritmo de k-medias, podríamos comparar directamente la validez interna de ambos algoritmos  para determinar cuál es mejor para agrupar los datos a lo largo de una variedad de dimensiones (p. ej., conectividad, compacidad, etc.). \n",
    "\n",
    "\n",
    "- Hay dos tipos de agrupamiento jerárquico: \n",
    "  - Los métodos de agrupamiento jerárquico divisivo comienzan con el conjunto de datos completo X y lo dividen en dos segmentos de mercado en un primer paso. Luego, cada uno de los segmentos se divide nuevamente en dos segmentos. Este proceso continúa hasta que cada consumidor tiene su propio segmento de mercado.\n",
    "  - El agrupamiento jerárquico aglomerativo aborda la tarea desde el otro extremo. El punto de partida es que cada consumidor representa su propio segmento de mercado (n grupos únicos). Paso a paso, los dos segmentos de mercado más cercanos entre sí se fusionan hasta que el conjunto de datos completo forma un gran segmento de mercado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d26fe",
   "metadata": {},
   "source": [
    "### Enlaces\n",
    "\n",
    "- Los algoritmos de clustering jerárquico son únicos en el sentido de que requieren especificar:\n",
    " \n",
    "    - una medida de distancia\n",
    "    - un método de enlace o vinculación, \n",
    "\n",
    "\n",
    "- Por lo tanto, con nuestros datos de distancia estandarizados, podemos ajustar un algoritmo de agrupamiento jerárquico, pero como el algoritmo procede en forma de pares, debemos especificar con precisión cómo se unen estos pares. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18167e-6b44-43d7-b718-ae845b8f350f",
   "metadata": {},
   "source": [
    "\n",
    "- El método de enlace es el mecanismo para determinar esto y hay muchos métodos de vinculación entre los que elegir:\n",
    "\n",
    "   - *Enlace simple*: También conocido como técnica del vecino más cercano; en este método combinamos los clusters, basándonos en los dos puntos más cercanos de cada cluster.\n",
    "   - *Enlace completo (complete linkage - CL)* :  El enlace completo o técnica del vecino más lejano, es lo opuesto al enlace simple y combina los clusters encontrando la distancia máxima entre las observaciones de los clusters\n",
    "   - *Enlace promedio de grupo (average )* :El enlace promedio de grupo utiliza la mínima distancia promedio entre los grupos. Es decir, calculamos todas las distancias entre pares de ambos clusters, y calculamos el promedio.\n",
    "  - *Enlace usando centroides (Centroid)* Este método usa la mínima distancia entre los centroides del cluster.\n",
    "  - *Enlace de Ward*  une los clusters más cercanos entre sí minimizando la varianza dentro de cada grupo, buscando que los elementos dentro de un mismo cluster sean lo más homogéneos posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e53e1-612e-4392-a03b-428f894c9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Crear dos clusters claros y separados\n",
    "np.random.seed(42)\n",
    "cluster1 = np.random.normal(loc=[-2, 0], scale=0.3, size=(10, 2))\n",
    "cluster2 = np.random.normal(loc=[2, 0], scale=0.3, size=(10, 2))\n",
    "X = np.vstack([cluster1, cluster2])\n",
    "\n",
    "# Calcular centroides\n",
    "centroid1 = np.mean(X[:10], axis=0)\n",
    "centroid2 = np.mean(X[10:], axis=0)\n",
    "\n",
    "# Encontrar los puntos más cercanos y más lejanos entre clusters\n",
    "distances = []\n",
    "for i in range(10):\n",
    "    for j in range(10, 20):\n",
    "        dist = np.linalg.norm(X[i] - X[j])\n",
    "        distances.append((dist, i, j))\n",
    "min_dist = min(distances)\n",
    "max_dist = max(distances)\n",
    "min_points = (X[min_dist[1]], X[min_dist[2]])\n",
    "max_points = (X[max_dist[1]], X[max_dist[2]])\n",
    "\n",
    "# Graficar cada tipo de enlace en gráficos separados\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 18))\n",
    "fig.suptitle('Tipos de Enlaces en Clustering Jerárquico', fontsize=16)\n",
    "\n",
    "# Single Linkage\n",
    "axs[0, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[0, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[0, 0].plot([min_points[0][0], min_points[1][0]], \n",
    "               [min_points[0][1], min_points[1][1]], \n",
    "               'g--', linewidth=2, label='Single Linkage')\n",
    "axs[0, 0].set_title('Single Linkage')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Complete Linkage\n",
    "axs[0, 1].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[0, 1].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[0, 1].plot([max_points[0][0], max_points[1][0]], \n",
    "               [max_points[0][1], max_points[1][1]], \n",
    "               'r--', linewidth=2, label='Complete Linkage')\n",
    "axs[0, 1].set_title('Complete Linkage')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Average Linkage\n",
    "axs[1, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[1, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "for i in range(3):  # Visualización de conexiones promedio entre pares representativos\n",
    "    axs[1, 0].plot([X[i, 0], X[10 + i, 0]], [X[i, 1], X[10 + i, 1]], 'purple', linestyle='--', linewidth=1, alpha=0.6)\n",
    "axs[1, 0].plot([centroid1[0], centroid2[0]], [centroid1[1], centroid2[1]], '--', color='purple', linewidth=2, label='Average Linkage')\n",
    "axs[1, 0].set_title('Average Linkage')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Centroid Linkage\n",
    "axs[1, 1].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[1, 1].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[1, 1].plot([centroid1[0], centroid2[0]], \n",
    "               [centroid1[1], centroid2[1]], \n",
    "               'k--', linewidth=2, label='Centroid Linkage')\n",
    "axs[1, 1].set_title('Centroid Linkage')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Ward Linkage\n",
    "axs[2, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[2, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[2, 0].plot([centroid1[0], centroid2[0]], [centroid1[1], centroid2[1]], '--', color='orange', linewidth=2)\n",
    "axs[2, 0].plot([centroid1[0], (centroid1[0] + centroid2[0]) / 2], [centroid1[1], (centroid1[1] + centroid2[1]) / 2], \n",
    "               '--', color='orange', linewidth=1.5, label='Ward Linkage')\n",
    "axs[2, 0].set_title('Ward Linkage')\n",
    "axs[2, 0].legend()\n",
    "axs[2, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Quitar el último subplot vacío\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee515e31-b45e-4f28-837d-ef46a4de0241",
   "metadata": {},
   "source": [
    "   \n",
    "- Es importante señalar que, al igual que las medidas de distancia, no existe una guía en la literatura sobre cuál es el mejor método de enlace.\n",
    "\n",
    "\n",
    "- La selección del método de enlace generalmente depende de las preferencias específicas del problema o disciplina, por ejemplo, el enlace centroide es popular entre los genetistas y ward entre los economistas.\n",
    "\n",
    "\n",
    "- Se recomienda que se comparen varios métodos de enlace para descubrir patrones naturales de la manera más eficiente posible.\n",
    "\n",
    "\n",
    "- Es importante reiterar que solo los algoritmos jerárquicos requieren la especificación de un método de vinculación, sin embargo, todos los algoritmos de agrupamiento requieren la especificación y el cálculo de una distancia entre las observaciones.\n",
    "\n",
    "    - La medida de distancia determina cómo se definen la similitud y la diferencia en el espacio de características, mientras que el método de enlace determina cómo se unen los elementos únicos, que se convierten en grupos más grandes.\n",
    "\n",
    "    - Se requieren medidas tanto de enlace como de distancia para el agrupamiento jerárquico, mientras que solo se requieren medidas de distancia para todas las demás técnicas de agrupamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76862f5a-69fe-4c87-a687-7e562a821bf4",
   "metadata": {},
   "source": [
    "# Ejemplo: Segmentación de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3030e-e732-48ce-b033-b6d45d1d3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Cargamos y vemos las primeras filas de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b7232-e9df-4270-b059-95dd128285ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy solo las variables de ingreso y puntaje de gasto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5a0bd-ad0a-442a-9f61-06ff825615fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "data_cluster_scaled = scaler.fit_transform(data_cluster)\n",
    "\n",
    "data_cluster_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d502cb-7d93-4074-be55-b4278b49cdd3",
   "metadata": {},
   "source": [
    "### El dendograma\n",
    "\n",
    "\n",
    "El dendrograma es una representación gráfica del resultado del proceso de agrupamiento en forma de árbol. La construcción es relativamente sencilla y se hace de la siguiente forma:\n",
    "\n",
    "   1. En la parte inferior del gráfico se colocan las N observaciones iniciales.\n",
    "   2. La unión de elementos se representan por tres líneas rectas. Dos líneas son perpendiculares a los elementos que se van a unir, y su altura va a estar dada por la distancia que hay entre los elementos. La tercera línea, las une.\n",
    "   3. El proceso se repite hasta que todos los elementos están conectados por líneas rectas. \n",
    "\n",
    "Entonces cada vez que se fusionan dos elementos o clusters, el dendrograma muestra una conexión correspondiente al nivel de distancia/disimilitud en el que se produjo. Por lo tanto, si cortamos el dendrograma a un nivel de distancia dado, obtenemos un número de clusters existentes en ese nivel y los elementos que lo conforman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14315c5-c4b7-4460-be26-f718edc6c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Construir el dendrograma\n",
    "\n",
    "\n",
    "# figura\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "           orientation='top',\n",
    "           labels=data_cluster.index,\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5e1c0-8ada-40b3-ab25-27d438cc6bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c9720-2c1f-4572-a410-991039b1dbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04138f3d-3ce5-46c8-bd5c-2c5eecb59034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Crear un gráfico de dispersión de los datos con los clusters coloreados\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=data, x='Ingreso', y='Puntaje_Gasto', hue='Cluster_Agglo', palette='viridis', s=100)\n",
    "plt.title('Clusters de Clientes')\n",
    "plt.xlabel('Ingreso')\n",
    "plt.ylabel('Puntaje de Gasto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72846ea-285a-43e7-a02d-dfae74d97c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d71fd5-b224-4068-8734-ddaa8a9109ae",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "- DBSCAN (por su nombre en inglés *Density-based spatial clustering of applications with noise*) agrupa los datos en función de las densidades de las observaciones, mientras maneja el ruido de manera eficiente.  Es especialmente útil cuando tenemos datos con formas irregulares o ruido (es decir, puntos que no pertenecen a ningún grupo).\n",
    "\n",
    "- DBSCAN  incorpora  la noción de densidad. Si hay grupos de puntos de datos que existen en el mismo vencindario, estos se pueden ver como miembros del mismo cluster.\n",
    "\n",
    "\n",
    "- DBSCAN utiliza dos parámetros importantes:\n",
    "\n",
    "- **Eps** (o radio): Imagina que tienes una lupa. Esta lupa representa un radio que puedes \"poner\" alrededor de cada punto.\n",
    "- **minPts** (puntos mínimos): Define cuántos puntos deben estar dentro del radio para que un punto sea considerado “central” de un grupo.\n",
    "\n",
    "### Clases de puntos en DBSCAN\n",
    "\n",
    "Hay tres tipos de puntos en DBSCAN:\n",
    "\n",
    "- **Punto central**: Si hay suficientes puntos (minPts) dentro del radio de un punto, este punto se convierte en un \"centro de densidad\" o \"punto central\" de un grupo.\n",
    "- **Punto de borde**: Si un punto no tiene suficientes puntos en su radio para ser central, pero está dentro del radio de un punto central, es un \"punto de borde\". Forma parte del grupo, pero no es lo suficientemente denso para ser un centro.\n",
    "- **Punto ruido**: Un punto que no tiene suficiente densidad alrededor y tampoco está en el radio de un punto central. Este punto no pertenece a ningún grupo, se considera “ruido”.\n",
    "\n",
    "###  ¿Cómo se forma un grupo?\n",
    "\n",
    "DBSCAN comienza eligiendo un punto al azar. Si este punto tiene suficiente densidad (es decir, tiene al menos minPts puntos dentro de su radio), se convierte en un punto central y se empieza a expandir el grupo desde ahí. Expande su \"zona de influencia\" a otros puntos que también tienen la densidad necesaria, conectando puntos densos hasta que no puede expandirse más.\n",
    "\n",
    "### Identificación de ruido\n",
    "\n",
    "Si un punto no cumple con los requisitos de densidad ni pertenece al radio de un punto central, DBSCAN lo marca como ruido y lo ignora. Estos puntos ruidosos pueden ser outliers en los datos, que no pertenecen a ningún grupo claro.\n",
    "\n",
    "###  Ventajas de DBSCAN\n",
    "\n",
    "- **Flexibilidad en la forma de los grupos**: A diferencia de K-means, DBSCAN no asume que los grupos son esféricos; puede manejar grupos de formas irregulares.\n",
    "- **No necesita especificar el número de clusters**: Solo especificas el radio (Eps) y la densidad mínima (minPts), y DBSCAN detecta cuántos clusters hay.\n",
    "- **Identificación de outliers**: Los puntos de ruido son identificados de manera automática, lo que puede ser útil en muchos contextos.\n",
    "\n",
    "\n",
    "Veamos como funciona \n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_1.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_2.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_3.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_4.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_5.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_6.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_7.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_8.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_9.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_10.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_11.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_12.png\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial_14.png\" />\n",
    "</div>\n",
    "### Todos los pasos\n",
    "\n",
    "<div style=\"max-width:400px\">\n",
    "    <img src = \"figs/DBSCAN_tutorial.gif\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a823f-7e25-4a72-8ebe-326c34ee4a61",
   "metadata": {},
   "source": [
    "##  Incorporando más dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782dc7b-ad70-408e-a5ac-4549e5a8cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear grupos etarios\n",
    "bins = [17, 24, 34, 44, 54, 64, float('inf')]\n",
    "labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "data['Grupo_Etario'] = pd.cut(data['Edad'], bins=bins, labels=labels)\n",
    "\n",
    "# Mostrar las primeras filas con la nueva variable\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d8f6b-c8f0-41c9-b05c-79cd09563d3e",
   "metadata": {},
   "source": [
    "### ** Al margen Distancia de Gower**\n",
    "\n",
    "Supongamos que tenemos los siguientes datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3591e1-dd1d-4c1b-8088-4f1b3f686ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creamos un diccionario\n",
    "dictionary = {\"Edad\": [22, 25, 30, 38, 42, 47, 55, 62, 61, 90], \n",
    "              \"Genero\": [\"M\", \"M\", \"F\", \"F\", \"F\", \"M\", \"M\", \"M\", \"M\", \"M\"], \n",
    "              \"Estado_Civil\": [\"Soltero\", \"Soltero\", \"Soltero\", \"Casado\", \"Casado\", \"Soltero\", \"Casado\", \"Divorciado\", \"Casado\", \"Divorciado\"], \n",
    "              \"Salario\": [18000, 23000, 27000, 32000, 34000, 20000, 40000, 42000, 25000, 70000], \n",
    "              \"tiene_hijos\": [False, False, False, True, True, False, False, False, False, True], \n",
    "              \"Volumen_compras\": [\"Bajo\", \"Bajo\", \"Bajo\", \"Alto\", \"Alto\", \"Bajo\", \"Medio\", \"Medio\", \"Medio\", \"Bajo\"]}\n",
    "\n",
    "# Creamos un Pandas DataFrame \n",
    "D = pd.DataFrame.from_dict(dictionary)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042294d-405e-4089-9877-595af6d56f42",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La distancia de Gower es especialmente útil en marketing porque permite trabajar con variables mixtas (numéricas y categóricas):\n",
    "\n",
    "La distancia de Gower entre dos observaciones i y j se define como:\n",
    "\n",
    "$d_{ij} = \\frac{\\sum_{k=1}^p w_k \\delta_{ijk} s_{ijk}}{\\sum_{k=1}^p w_k \\delta_{ijk}}$\n",
    "\n",
    "Donde:\n",
    "- $s_{ijk}$ es la contribución de la variable k a la distancia total\n",
    "- $w_k$ es el peso de la variable k (normalmente $w_k = 1$)\n",
    "- $\\delta_{ijk}$ es la variable indicadora de comparabilidad:\n",
    "  - $\\delta_{ijk} = 0$ si el valor es faltante para alguna de las observaciones\n",
    "  - $\\delta_{ijk} = 1$ si el valor está presente en ambas observaciones\n",
    "\n",
    "Para cada tipo de variable, $s_{ijk}$ se calcula de manera diferente:\n",
    "\n",
    "Para variables numéricas:\n",
    "$s_{ijk} = \\frac{|x_{ik} - x_{jk}|}{range_k}$\n",
    "\n",
    "Para variables categóricas:\n",
    "$s_{ijk} = \\begin{cases} 0 & \\text{si } x_{ik} = x_{jk} \\\\ 1 & \\text{si } x_{ik} \\neq x_{jk} \\end{cases}$\n",
    "\n",
    "Para variables binarias:\n",
    "$s_{ijk} = \\begin{cases} 0 & \\text{si } x_{ik} = x_{jk} = 1 \\\\ 0 & \\text{si } x_{ik} = x_{jk} = 0 \\\\ 1 & \\text{en otro caso} \\end{cases}$\n",
    "\n",
    "Donde:\n",
    "- $range_k$ es el rango (máximo - mínimo) de la variable k\n",
    "- $x_{ik}$ es el valor de la variable k para la observación i\n",
    "- $x_{jk}$ es el valor de la variable k para la observación j\n",
    "\n",
    "\n",
    "Es decir:\n",
    "\n",
    "    - Para una característica numérica, la diferencia parcial entre dos clientes i y j es la resta entre sus valores en la característica específica (en valor absoluto) dividida por el rango total de la característica. El rango de salario es 52000 (70000–18000) mientras que el rango de edad es 68 (90–22). \n",
    "    Note, hay que tener en cuenta si existen outliers o valores atípicos. Un valor erróneo extremadamente grande o pequeño afectaría directamente el rango y, por lo tanto, las diferencias en esa característica, distorsionando su importancia.\n",
    "\n",
    "    - Para una característica categórica, la diferencia parcial entre dos clientes es uno cuando ambos clientes tienen un valor diferente para esta característica. Cero en caso contrario.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93c595-ab38-45dc-81ab-a3e7104c8163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c854de-4c73-4d54-83bd-2ca4a2103aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c1e0e-9459-4fda-89f2-1a84070b7648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4159a-6e85-4d18-b331-7b3ce74b2cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210e263-4769-43f0-85a7-98f98dc1bb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d19b0ceb-c2e7-4784-8fd3-8757514bf3ec",
   "metadata": {},
   "source": [
    "La Disimilitud de Gower entre ambos clientes es el promedio de disimilitudes parciales a lo largo de las diferentes características: \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{(0,044118 + 0 + 0 + 0,096154 + 0 + 0)}{ 6} = 0,023379. \n",
    "\\end{align}\n",
    "\n",
    "Como el valor es cercano a cero, podemos decir que ambos clientes son muy similares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4cb13-a8f5-410a-894d-7ad50fc8ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "\n",
    "distance_matrix = gower.gower_matrix(D)\n",
    "pd.DataFrame(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df99496-a58f-4fae-bfbb-222345c2a965",
   "metadata": {},
   "source": [
    "### **retomando** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec88bf-5d87-47aa-b3b5-963597535c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy of the DataFrame slice to avoid the warning\n",
    "data_gower = data[['Puntaje_Gasto', 'Ingreso', 'Genero', 'Grupo_Etario']].copy()\n",
    "\n",
    "# Convert `Grupo_Etario` to string type\n",
    "data_gower['Grupo_Etario'] = data_gower['Grupo_Etario'].astype(str)\n",
    "\n",
    "# Encode categorical variables (like `Genero` and `Grupo_Etario`)\n",
    "label_encoder = LabelEncoder()\n",
    "data_gower['Genero'] = label_encoder.fit_transform(data_gower['Genero'])\n",
    "data_gower['Grupo_Etario'] = label_encoder.fit_transform(data_gower['Grupo_Etario'])\n",
    "\n",
    "data_gower.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212f189-a83d-44dd-bf9d-1584e8ae536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "\n",
    "distance_matrix = gower.gower_matrix(data_gower)\n",
    "\n",
    "pd.DataFrame(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ffb71-7de0-4c08-a08c-8c906c20af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "#Min samples\n",
    "samples_gower = 2*4 # Sander et al., (1998) 2*dim\n",
    "\n",
    "# Usar el método del codo para encontrar el valor óptimo de eps\n",
    "neigh = NearestNeighbors(n_neighbors=samples_gower)\n",
    "nbrs = neigh.fit(distance_matrix)\n",
    "distances, indices = nbrs.kneighbors(distance_matrix)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)\n",
    "plt.show()\n",
    "\n",
    "i = np.arange(len(distances))\n",
    "knee_gower = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f02f3-18ad-4d0e-8d16-acf9bc8c716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_knee=(distances[knee_gower.knee]/2).round(2)-0.08\n",
    "\n",
    "eps_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67267a8c-9b1a-4b06-8677-8e2ab72bdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = DBSCAN(eps=eps_knee, min_samples=samples_gower, metric=\"precomputed\")\n",
    "\n",
    "db.fit(distance_matrix)\n",
    "\n",
    "# Asignar las etiquetas de los clusters a los datos\n",
    "labels = db.labels_\n",
    "data['Cluster_DBSCAN_Gower'] = labels\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae781c-ba32-4750-a7a8-5c56faab959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describir los clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956fd80",
   "metadata": {},
   "source": [
    "### Tarea para la casa: Comparación con K-medias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
